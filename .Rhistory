arm_1 <- read.csv("C:/Users/ff242/Desktop/Kasap_2010_KM_16..csv", header=FALSE)
arm_1[1,] <- 1
arm_1[24,2] <- 0
tot.events<-"NA" #tot.events = total no. of events reported. If not reported, then tot.events="NA"
arm.id<-1 #arm indicator
digizeit<- arm_1
t.S<-digizeit[,1]
S<-digizeit[,2]
t.risk<- seq(1,137, by=8)
percents <- arm_1[seq(1, 24, by=2),2]
n.risk <- c(9,9,9,9,9,9, 9*cumprod(percents))
n.risk <- floor(n.risk)
lower <- c(1,2,2,2,2,2,2,2,2,2,2,2,4,10,12,16,20,22)
upper <- c(1,1,1,1,1,1,1,1,1,1,1,1,3,9 ,11,15,19,11)
n.risk
t.risk
n.risk <- c(9,9,9,9,9,9, 9*cumprod(percents))
ceiling(n.risk)
cumprod(percents)
30*cumprod(percents)
30*9*cumprod(percents)
n.risk
t.risk
View(arm_1)
arm_1[2,2] <- 1
n.risk <- c(rep(9, 11), 9*cumprod(percents))
n.risk
percents
n.risk <- c(rep(9, 10), 9*cumprod(percents))
percents
cumprod(percents)
t.risk
percents
cumprod percents
cumprod(percents)
t.risk
n.risk
floor(n.risk)
c.bind(t.risk, floor(n.risk))
cbind(t.risk, floor(n.risk))
n.risk <- c(rep(9, 12), 9*cumprod(percents))
cbind(t.risk, floor(n.risk))
percents
cumprod(percetns[1:8])
cumprod(percetns[1:8])
cumprod(percents[1:8])
0.39*9
percent[3:5]
percents[3:5]
prod(percents[3:5])
9*prod(percents[3:5])
t.risk
n.risk
cbind(t.ris, n.risk)
cbind(t.risk, n.risk)
t.risk
n.risk <- c(rep(20, 10), 9,7,7,7,6,5,4,3)
arm_1 <- read.csv("C:/Users/ff242/Desktop/Kasap_2010_KM_16..csv", header=FALSE)
arm_1[1,] <- 1
arm_1[2,2] <- 1
arm_1[24,2] <- 0
tot.events<-"NA" #tot.events = total no. of events reported. If not reported, then tot.events="NA"
arm.id<-1 #arm indicator
###END FUNCTION INPUTS
#Read in survival times read by digizeit
digizeit<- arm_1
t.S<-digizeit[,1]
S<-digizeit[,2]
#Read in published numbers at risk, n.risk, at time, t.risk, lower and upper
# indexes for time interval
t.risk<- seq(1,137, by=8)
n.risk <- c(rep(20, 10), 9,7,7,7,6,5,4,3)
arm_1
t.S
lower <- c(1,2,2,2,2,2,2,2,2,2,2,2,4,10,12,16,20,22)
upper <- c(1,1,1,1,1,1,1,1,1,1,1,1,3,9 ,11,15,19,11)
n.int<-length(n.risk)
n.t<- upper[n.int]
#Initialise vectors
arm<-rep(arm.id,n.risk[1])
n.censor<- rep(0,(n.int-1))
n.hat<-rep(n.risk[1]+1,n.t)
cen<-rep(0,n.t)
d<-rep(0,n.t)
KM.hat<-rep(1,n.t)
last.i<-rep(1,n.int)
sumdL<-0
if (n.int > 1){
#Time intervals 1,...,(n.int-1)
for (i in 1:(n.int-1)){
#First approximation of no. censored on interval i
n.censor[i]<- round(n.risk[i]*S[lower[i+1]]/S[lower[i]]- n.risk[i+1])
#Adjust tot. no. censored until n.hat = n.risk at start of interval (i+1)
while((n.hat[lower[i+1]]>n.risk[i+1])||((n.hat[lower[i+1]]<n.risk[i+1])&&(n.censor[i]>0))){
if (n.censor[i]<=0){
cen[lower[i]:upper[i]]<-0
n.censor[i]<-0
}
if (n.censor[i]>0){
cen.t<-rep(0,n.censor[i])
for (j in 1:n.censor[i]){
cen.t[j]<- t.S[lower[i]] +
j*(t.S[lower[(i+1)]]-t.S[lower[i]])/(n.censor[i]+1)
}
#Distribute censored observations evenly over time. Find no. censored on each time interval.
cen[lower[i]:upper[i]]<-hist(cen.t,breaks=t.S[lower[i]:lower[(i+1)]],
plot=F)$counts
}
#Find no. events and no. at risk on each interval to agree with K-M estimates read from curves
n.hat[lower[i]]<-n.risk[i]
last<-last.i[i]
for (k in lower[i]:upper[i]){
if (i==1 & k==lower[i]){
d[k]<-0
KM.hat[k]<-1
}
else {
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
}
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
if (d[k] != 0) last<-k
}
n.censor[i]<- n.censor[i]+(n.hat[lower[i+1]]-n.risk[i+1])
}
if (n.hat[lower[i+1]]<n.risk[i+1]) n.risk[i+1]<-n.hat[lower[i+1]]
last.i[(i+1)]<-last
}
}
#Time interval n.int.
if (n.int>1){
#Assume same censor rate as average over previous time intervals.
n.censor[n.int]<- min(round(sum(n.censor[1:(n.int-1)])*(t.S[upper[n.int]]-
t.S[lower[n.int]])/(t.S[upper[(n.int-1)]]-t.S[lower[1]])), n.risk[n.int])
}
if (n.int==1){n.censor[n.int]<-0}
if (n.censor[n.int] <= 0){
cen[lower[n.int]:(upper[n.int]-1)]<-0
n.censor[n.int]<-0
}
if (n.censor[n.int]>0){
cen.t<-rep(0,n.censor[n.int])
for (j in 1:n.censor[n.int]){
cen.t[j]<- t.S[lower[n.int]] +
j*(t.S[upper[n.int]]-t.S[lower[n.int]])/(n.censor[n.int]+1)
}
cen[lower[n.int]:(upper[n.int]-1)]<-hist(cen.t,breaks=t.S[lower[n.int]:upper[n.int]],
plot=F)$counts
}
#Find no. events and no. at risk on each interval to agree with K-M estimates read from curves
n.hat[lower[n.int]]<-n.risk[n.int]
last<-last.i[n.int]
for (k in lower[n.int]:upper[n.int]){
if(KM.hat[last] !=0){
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))} else {d[k]<-0}
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
#No. at risk cannot be negative
if (n.hat[k+1] < 0) {
n.hat[k+1]<-0
cen[k]<-n.hat[k] - d[k]
}
if (d[k] != 0) last<-k
}
#If total no. of events reported, adjust no. censored so that total no. of events agrees.
if (tot.events != "NA"){
if (n.int>1){
sumdL<-sum(d[1:upper[(n.int-1)]])
#If total no. events already too big, then set events and censoring = 0 on all further time intervals
if (sumdL >= tot.events){
d[lower[n.int]:upper[n.int]]<- rep(0,(upper[n.int]-lower[n.int]+1))
cen[lower[n.int]:(upper[n.int]-1)]<- rep(0,(upper[n.int]-lower[n.int]))
n.hat[(lower[n.int]+1):(upper[n.int]+1)]<- rep(n.risk[n.int],(upper[n.int]+1-lower[n.int]))
}
}
#Otherwise adjust no. censored to give correct total no. events
if ((sumdL < tot.events)|| (n.int==1)){
sumd<-sum(d[1:upper[n.int]])
while ((sumd > tot.events)||((sumd< tot.events)&&(n.censor[n.int]>0))){
n.censor[n.int]<- n.censor[n.int] + (sumd - tot.events)
if (n.censor[n.int]<=0){
cen[lower[n.int]:(upper[n.int]-1)]<-0
n.censor[n.int]<-0
}
if (n.censor[n.int]>0){
cen.t<-rep(0,n.censor[n.int])
for (j in 1:n.censor[n.int]){
cen.t[j]<- t.S[lower[n.int]] +
j*(t.S[upper[n.int]]-t.S[lower[n.int]])/(n.censor[n.int]+1)
}
cen[lower[n.int]:(upper[n.int]-1)]<-hist(cen.t,breaks=t.S[lower[n.int]:upper[n.int]],
plot=F)$counts
}
n.hat[lower[n.int]]<-n.risk[n.int]
last<-last.i[n.int]
for (k in lower[n.int]:upper[n.int]){
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
if (k != upper[n.int]){
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
#No. at risk cannot be negative
if (n.hat[k+1] < 0) {
n.hat[k+1]<-0
cen[k]<-n.hat[k] - d[k]
}
}
if (d[k] != 0) last<-k
}
sumd<- sum(d[1:upper[n.int]])
}
}
}
write.table(matrix(c(t.S,n.hat[1:n.t],d,cen),ncol=4,byrow=F),paste(path,KMdatafile,sep=""),sep="\t")
### Now form IPD ###
#Initialise vectors
t.IPD<-rep(t.S[n.t],n.risk[1])
event.IPD<-rep(0,n.risk[1])
#Write event time and event indicator (=1) for each event, as separate row in t.IPD and event.IPD
k=1
for (j in 1:n.t){
if(d[j]!=0){
t.IPD[k:(k+d[j]-1)]<- rep(t.S[j],d[j])
event.IPD[k:(k+d[j]-1)]<- rep(1,d[j])
k<-k+d[j]
}
}
#Write censor time and event indicator (=0) for each censor, as separate row in t.IPD and event.IPD
for (j in 1:(n.t-1)){
if(cen[j]!=0){
t.IPD[k:(k+cen[j]-1)]<- rep(((t.S[j]+t.S[j+1])/2),cen[j])
event.IPD[k:(k+cen[j]-1)]<- rep(0,cen[j])
k<-k+cen[j]
}
}
#Output IPD
IPD<-matrix(c(t.IPD,event.IPD,arm),ncol=3,byrow=F)
IPD
rm(list=ls())
library(rotl)
taxa <- c("Trichogramma_pretiosum")
tnrs_match_names(taxa,context_name = "Animals")
tnrs_match_names("Canis_lupus",context_name = "Animals")
tnrs_match_names("Aedes_australis",context_name = "Animals")
tnrs_match_names("Xiphophorus_meyeri",context_name = "Animals")
tnrs_match_names("Trichogramma acacioi",context_name = "Animals")
tnrs_match_names("Trichogramma_acacioi",context_name = "Animals")
tnrs_match_names("Trichogramma_acantholydae",context_name = "Animals")
tnrs_match_names("Aphis citricidus",context_name = "Animals")
tnrs_match_names("Aphis_citricidus",context_name = "Animals")
tnrs_match_names("Tinocallis_dalbergicola",context_name = "Animals")
tnrs_match_names("Tetrastichus_abalosi",context_name = "Animals")
tnrs_match_names("Telenomus chrysopae",context_name = "Animals")
tnrs_match_names("Telenomus_chrysopae",context_name = "Animals")
tnrs_match_names("Sphenomorphus_maculatus",context_name = "Animals")
tnrs_match_names("Larutia_seribuatensis",context_name = "Animals")
tnrs_match_names("Sceloporus_consobrinus",context_name = "Animals")
tnrs_match_names("Sardinops_caeruleus",context_name = "Animals")
tnrs_match_names("Rhyncaphytoptus_abiesis",context_name = "Animals")
tnrs_match_names("Australopalpus_alphitoniae",context_name = "Animals")
tnrs_match_names("Pseudodiaptomus_inopinus",context_name = "Animals")
tnrs_match_names("Pseudodiaptomus_andamanensis",context_name = "Animals")
tnrs_match_names("Pseudodiaptomus_actusus",context_name = "Animals")
tnrs_match_names("Pseudococcus_aberrans",context_name = "Animals")
tnrs_match_names("Caryedon_serratus",context_name = "Animals")
tnrs_match_names("Circus_melanoleucos",context_name = "Animals")
tnrs_match_names("Hippocampus_alatus",context_name = "Animals")
tnrs_match_names("Muscidifurax_raptorellus",context_name = "Animals")
tnrs_match_names("Gryllus_bimaculatus",context_name = "Animals")
tnrs_match_names("Gryllus_abditus",context_name = "Animals")
tnrs_match_names("Haliotis_asinina",context_name = "Animals")
tnrs_match_names("perca_falcata",context_name = "Animals")
tnrs_match_names("Phallocryptus_sublettei",context_name = "Animals")
tnrs_match_names("Pleuronectes_quadrituberculatus",context_name = "Animals")
tnrs_match_names("Planococcus_aemulor",context_name = "Animals")
tnrs_match_names("Phyllonorycter_pomonella",context_name = "Animals")
tnrs_match_names("Phyllonorycter_aarviki",context_name = "Animals")
tnrs_match_names("Phyllonorycter_abrasella",context_name = "Animals")
tnrs_match_names("Phyllonorycter_acanthus",context_name = "Animals")
tnrs_match_names("Penaeus_arambourgi",context_name = "Animals")
tnrs_match_names("Pediculaster_amerahae",context_name = "Animals")
tnrs_match_names("Patella_affinis",context_name = "Animals")
tnrs_match_names("Patella_albicosta",context_name = "Animals")
tnrs_match_names("Poecile_cinctus",context_name = "Animals")
tnrs_match_names("Paracoccus_abnormalis",context_name = "Animals")
tnrs_match_names("ophryotrocha_permanni",context_name = "Animals")
tnrs_match_names("chrysoperla_adami",context_name = "Animals")
tnrs_match_names("cicadulina_anesta",context_name = "Animals")
tnrs_match_names("Neoseiulus_accessus",context_name = "Animals")
tnrs_match_names("Myzus_adjugae",context_name = "Animals")
tnrs_match_names("Mythimna_unipuncta",context_name = "Animals")
tnrs_match_names("Mabuya_meridensis",context_name = "Animals")
tnrs_match_names("Larus_hartalbi",context_name = "Animals")
tnrs_match_names("Largus_biaculatus",context_name = "Animals")
tnrs_match_names("Largus_bimaculatus",context_name = "Animals")
tnrs_match_names("Largus_bipupulatus",context_name = "Animals")
tnrs_match_names("Lacerta_schreiberi",context_name = "Animals")
tnrs_match_names("Hyalopterus_amygdali",context_name = "Animals")
tnrs_match_names("Daphnosis_australis",context_name = "Animals")
tnrs_match_names("Daphnopsis_australis",context_name = "Animals")
tnrs_match_names("Daphnia_australis",context_name = "Animals")
tnrs_match_names("Diaptomus_acutilobatus",context_name = "Animals")
tnrs_match_names("Diaptomus_affinis",context_name = "Animals")
tnrs_match_names("Diaptomus_armatus",context_name = "Animals")
tnrs_match_names("Diaptomus_azureus",context_name = "Animals")
tnrs_match_names("Diglyphus isaea",context_name = "Animals")
tnrs_match_names("Diglyphus_isaea",context_name = "Animals")
tnrs_match_names("Diploar_labyrinthiformis",context_name = "Animals")
tnrs_match_names("echinometra_insularis",context_name = "Animals")
tnrs_match_names("echinometra_vanbrunti",context_name = "Animals")
tnrs_match_names("Echinogammarus_acarinatus",context_name = "Animals")
# Set up data
data <- read.delim("Mapdata20230519.txt", h=T, stringsAsFactors = TRUE)
###-----------------------------------------------------###
### Multilevel meta-analysis using Metafor              ###
### Author: Fay Frost [fay.frost@liverpool.ac.uk]             ###
### Code adapted from Liam Dougherty.
### University of Liverpool                             ###
### Date: August 2023                                   ###
###-----------------------------------------------------###
############################################ Preamble ######################################################
rm(list=ls()) # Clear R environment
library(metafor)
library(ggplot2)
library(ape)
library(rotl)
library(multcomp)
library(dplyr)
# To install the orchaRd package:
install.packages("pacman")
install.packages("pacman")
pacman::p_load(devtools, tidyverse, metafor, patchwork, R.rsp, emmeans)
devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
install.packages("orchaRd")
devtools::install_github("daniel1noble/orchaRd", force = TRUE)
sessionInfo()
install.packages("installr")
library(installr)
updateR()
updateR()
setwd("C:/Users/ff242/Documents/GitHub/Thermal_Fertility_Meta-Analysis")
library(dplyr)
papers <- read_csv("Data/Raw Data/Survival project all data Included Papers.csv")
library(readr)
papers <- read_csv("Data/Raw Data/Survival project all data Included Papers.csv")
inc_papers <- subset(papers, Decision == "Include")
paper.list <- as.factor(inc_papers$`Paper code`)
Survival_data<- read_csv("Data/Raw Data/Survival project all data RAW.csv")
used.papers <- as.factor(Survival_data$`Paper code`)
sort(paper.list[which(paper.list %in% used.papers == FALSE)])
## make subset of the papers that aren't included but say they are
notin_papers <- inc_papers[inc_papers$`Paper code` %in% paper.list[which(paper.list %in% used.papers == FALSE)],]
sort(notin_papers)
sort(notin_papers$`Paper code`)
papers <- read_csv("Data/Raw Data/Survival project all data Included Papers.csv")
inc_papers <- subset(papers, Decision == "Include")
paper.list <- as.factor(inc_papers$`Paper code`)
Survival_data<- read_csv("Data/Raw Data/Survival project all data RAW.csv")
used.papers <- as.factor(Survival_data$`Paper code`)
sort(paper.list[which(paper.list %in% used.papers == FALSE)])
## make subset of the papers that aren't included but say they are
notin_papers <- inc_papers[inc_papers$`Paper code` %in% paper.list[which(paper.list %in% used.papers == FALSE)],]
